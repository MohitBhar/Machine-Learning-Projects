{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Ctrl+Enter) will list all files under the input directory\n\nimport os\n        \n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os #Importing the OS library to perform tasks such as shifting of images to folder etc.\nimport csv #Importing the csv library to use csv.reader function to read a file\ndata = {}  #data with key as the class of the image and the values as the array with all the images \n#belonging to that class\nwith open('/kaggle/input/state-farm-distracted-driver-detection/driver_imgs_list.csv') as f:\n    reader = csv.reader(f)\n    next(reader) #Skipping the header row\n    for row in f:\n        row = row.split(\",\")\n        key = row[1]\n        if(key in data):\n            data[key].append(row[2])\n        else:\n            data[key]=[row[2]]\n#Creating the data dictionary as the key and values specified above","metadata":{"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class_list = list(data.keys()) #The various class in the dataset","metadata":{"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"import os\nos.mkdir('/kaggle/working/master_data') #Creating directory to store the master-data\nos.mkdir('/kaggle/working/master_data/training') #Creating directory to store the training data\nos.mkdir('/kaggle/working/master_data/validation') #Creating directory to store the validation data","metadata":{"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"for class_ in class_list:\n    os.mkdir('/kaggle/working/master_data/training/'+class_) #Creating different directory corresponding to each class in the\n    #training and validation directory so as to store images belonging to each class in different folders\n    #This would enable us to use the ImageDataGenerator library\n    os.mkdir('/kaggle/working/master_data/validation/'+class_)\n    #Performing the same task for the validation directory","metadata":{"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"from shutil import copyfile #Copyfile lib to copy file from source to destination directory\nsplit_size = 0.8 #The ratio in which the validation and training data will be split\n\nfor class_, images in data.items():\n    train_size = int(split_size * len(images))\n    train_images = images[:train_size] #The training images\n    test_images = images[train_size:] #The testing images\n    #The for loops are used for storing the data in the corresponding class from the train directory\n    for image in train_images:\n        image = image.split(\"\\n\") \n        source = os.path.join('/kaggle/input/state-farm-distracted-driver-detection/imgs/train',class_,image[0]) #source directory\n        dest = os.path.join('/kaggle/working/master_data/training',class_,image[0]) #destination directory\n        copyfile(source,dest) # copying the file from source to dest\n    ##The for loops are used for storing the data in the corresponding class from the train directory\n    for image in test_images:\n        image = image.split(\"\\n\")\n        source = os.path.join('/kaggle/input/state-farm-distracted-driver-detection/imgs/train',class_,image[0]) #Source Directory\n        dest = os.path.join('/kaggle/working/master_data/validation',class_,image[0]) #Destination Directory\n        copyfile(source,dest) #Copying file from source to destination\n    ","metadata":{"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf #Importing tensorflow library\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator #Importing ImageDataGenerator library to easily manage \n#and create the training and validation dataset\nfrom tensorflow.keras.optimizers import Adam\n#Adam Optimizer\nfrom tensorflow.keras.callbacks import EarlyStopping\n#Callbacks to stop the epochs if the change in accuracy is not significant\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten,Dropout\n#Importing various layers","metadata":{"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"#Creating the model by adding various layers such as the CONV2D, MaxPooling2D, dropout layer, dense layer etc.\nmodel = tf.keras.models.Sequential([\n    Conv2D(32,(2,2),activation='relu',input_shape = (128,128,3),kernel_initializer='glorot_normal',padding='same'),\n    MaxPooling2D(pool_size = (2,2),),\n    Conv2D(64,(2,2),activation = 'relu',padding='same',kernel_initializer='glorot_normal'),\n    MaxPooling2D(pool_size = (2,2)),\n    Conv2D(128,(2,2),activation = 'relu',padding='same',kernel_initializer='glorot_normal'),\n    MaxPooling2D(pool_size = (2,2)),\n    Dropout(0.5),\n    Flatten(),\n    Dense(500,activation = 'relu',kernel_initializer='glorot_normal'),\n    Dropout(0.5),\n    Dense(10,activation = 'softmax',kernel_initializer='glorot_normal')\n])\n#Compiling the model with the loss, optimizer and metrics used for testing the model\nmodel.compile(optimizer='rmsprop',loss = 'categorical_crossentropy',\n             metrics = ['accuracy'])\n#Checking the model summary if correct or not\nmodel.summary()","metadata":{"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Model: \"sequential_3\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_11 (Conv2D)           (None, 128, 128, 32)      416       \n_________________________________________________________________\nmax_pooling2d_11 (MaxPooling (None, 64, 64, 32)        0         \n_________________________________________________________________\nconv2d_12 (Conv2D)           (None, 64, 64, 64)        8256      \n_________________________________________________________________\nmax_pooling2d_12 (MaxPooling (None, 32, 32, 64)        0         \n_________________________________________________________________\nconv2d_13 (Conv2D)           (None, 32, 32, 128)       32896     \n_________________________________________________________________\nmax_pooling2d_13 (MaxPooling (None, 16, 16, 128)       0         \n_________________________________________________________________\ndropout_6 (Dropout)          (None, 16, 16, 128)       0         \n_________________________________________________________________\nflatten_3 (Flatten)          (None, 32768)             0         \n_________________________________________________________________\ndense_6 (Dense)              (None, 500)               16384500  \n_________________________________________________________________\ndropout_7 (Dropout)          (None, 500)               0         \n_________________________________________________________________\ndense_7 (Dense)              (None, 10)                5010      \n=================================================================\nTotal params: 16,431,078\nTrainable params: 16,431,078\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"train_dir = '/kaggle/working/master_data/training' #Directory containing the training data\ntest_dir = '/kaggle/working/master_data/validation' #Directory containing the testing data\n\ntrain_data_gen = ImageDataGenerator(1.0/255) #Image Data Generator for the trainging dataset\ntrain_generator = train_data_gen.flow_from_directory(\n    train_dir , target_size = (128,128), class_mode = 'categorical',\n    batch_size = 128\n) #Creating the training_generator with specified parameters\ntest_data_gen = ImageDataGenerator(1.0/255) #Image Data Generator for the validation dataset\ntest_generator = test_data_gen.flow_from_directory(\n    test_dir , target_size = (128,128), class_mode = 'categorical',\n    batch_size = 128\n) #Creating the validation_generator with specified parameters\n","metadata":{"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Found 17934 images belonging to 10 classes.\nFound 4490 images belonging to 10 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"es = EarlyStopping(monitor = 'accuracy',patience = 3, min_delta = 0.01)\n#Defining the callback to stop the model with accuracy as the metrics and min_delta 1% and patience 3 epochs","metadata":{"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"model.fit_generator(train_generator,epochs = 20, verbose =1, validation_data=test_generator,callbacks=[es])","metadata":{"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Epoch 1/20\n141/141 [==============================] - 290s 2s/step - loss: 67.9278 - accuracy: 0.3987 - val_loss: 5.3390 - val_accuracy: 0.1486\nEpoch 2/20\n141/141 [==============================] - 289s 2s/step - loss: 0.8968 - accuracy: 0.8457 - val_loss: 9.8045 - val_accuracy: 0.1539\nEpoch 3/20\n141/141 [==============================] - 303s 2s/step - loss: 0.4198 - accuracy: 0.9213 - val_loss: 7.7563 - val_accuracy: 0.1904\nEpoch 4/20\n141/141 [==============================] - 288s 2s/step - loss: 0.3425 - accuracy: 0.9368 - val_loss: 7.2158 - val_accuracy: 0.2080\nEpoch 5/20\n141/141 [==============================] - 305s 2s/step - loss: 0.1958 - accuracy: 0.9564 - val_loss: 10.9925 - val_accuracy: 0.2336\nEpoch 6/20\n141/141 [==============================] - 288s 2s/step - loss: 0.4608 - accuracy: 0.9414 - val_loss: 12.1593 - val_accuracy: 0.2285\nEpoch 7/20\n141/141 [==============================] - 308s 2s/step - loss: 0.1280 - accuracy: 0.9747 - val_loss: 12.8780 - val_accuracy: 0.2354\nEpoch 8/20\n141/141 [==============================] - 290s 2s/step - loss: 0.0893 - accuracy: 0.9790 - val_loss: 13.9765 - val_accuracy: 0.2350\nEpoch 9/20\n141/141 [==============================] - 303s 2s/step - loss: 0.1573 - accuracy: 0.9759 - val_loss: 14.6141 - val_accuracy: 0.2454\nEpoch 10/20\n141/141 [==============================] - 289s 2s/step - loss: 0.0708 - accuracy: 0.9843 - val_loss: 19.8748 - val_accuracy: 0.2394\nEpoch 11/20\n141/141 [==============================] - 290s 2s/step - loss: 0.0781 - accuracy: 0.9838 - val_loss: 13.7125 - val_accuracy: 0.2383\nEpoch 12/20\n141/141 [==============================] - 302s 2s/step - loss: 0.0531 - accuracy: 0.9874 - val_loss: 19.9976 - val_accuracy: 0.2296\nEpoch 13/20\n141/141 [==============================] - 287s 2s/step - loss: 0.0704 - accuracy: 0.9855 - val_loss: 20.9309 - val_accuracy: 0.2412\n","output_type":"stream"},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7ff6ec5c2150>"},"metadata":{}}]},{"cell_type":"code","source":"import glob\nfrom skimage import io \nfrom skimage.transform import resize\nsize = (128,128)\nimage_dir = '/kaggle/input/state-farm-distracted-driver-detection/imgs/test'\nimage_list = glob.glob(image_dir+'/*')\nx_test= [] #Creating the testing dataset by iterating the test directory and resizing the images according to the expected data.\nfor i,imgfile in enumerate(image_list):\n    if(i%10000==0):\n        print(i)\n    img = io.imread(imgfile)\n    img = resize(img,size)\n    x_test.append(img)\n    #appending the current image to x_test\n","metadata":{"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"0\n","output_type":"stream"}]},{"cell_type":"code","source":"#Prediciting the result and printing it\nx_test = np.array(x_test) \nprint(x_test.shape)\ny_pred = model.predict(x_test)\nprint(y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}