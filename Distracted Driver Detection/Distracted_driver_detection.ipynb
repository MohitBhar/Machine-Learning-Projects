{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os #Importing the OS library to perform tasks such as shifting of images to folder etc.\n",
    "import csv #Importing the csv library to use csv.reader function to read a file\n",
    "data = {}  #data with key as the class of the image and the values as the array with all the images \n",
    "#belonging to that class\n",
    "with open('/kaggle/input/state-farm-distracted-driver-detection/driver_imgs_list.csv') as f:\n",
    "    reader = csv.reader(f)\n",
    "    next(reader) #Skipping the header row\n",
    "    for row in f:\n",
    "        row = row.split(\",\")\n",
    "        key = row[1]\n",
    "        if(key in data):\n",
    "            data[key].append(row[2])\n",
    "        else:\n",
    "            data[key]=[row[2]]\n",
    "#Creating the data dictionary as the key and values specified above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list = list(data.keys()) #The various class in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.mkdir('/kaggle/working/master_data') #Creating directory to store the master-data\n",
    "os.mkdir('/kaggle/working/master_data/training') #Creating directory to store the training data\n",
    "os.mkdir('/kaggle/working/master_data/validation') #Creating directory to store the validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for class_ in class_list:\n",
    "    os.mkdir('/kaggle/working/master_data/training/'+class_) #Creating different directory corresponding to each class in the\n",
    "    #training and validation directory so as to store images belonging to each class in different folders\n",
    "    #This would enable us to use the ImageDataGenerator library\n",
    "    os.mkdir('/kaggle/working/master_data/validation/'+class_)\n",
    "    #Performing the same task for the validation directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shutil import copyfile #Copyfile lib to copy file from source to destination directory\n",
    "split_size = 0.8 #The ratio in which the validation and training data will be split\n",
    "\n",
    "for class_, images in data.items():\n",
    "    train_size = int(split_size * len(images))\n",
    "    train_images = images[:train_size] #The training images\n",
    "    test_images = images[train_size:] #The testing images\n",
    "    #The for loops are used for storing the data in the corresponding class from the train directory\n",
    "    for image in train_images:\n",
    "        image = image.split(\"\\n\") \n",
    "        source = os.path.join('/kaggle/input/state-farm-distracted-driver-detection/imgs/train',class_,image[0]) #source directory\n",
    "        dest = os.path.join('/kaggle/working/master_data/training',class_,image[0]) #destination directory\n",
    "        copyfile(source,dest) # copying the file from source to dest\n",
    "    ##The for loops are used for storing the data in the corresponding class from the train directory\n",
    "    for image in test_images:\n",
    "        image = image.split(\"\\n\")\n",
    "        source = os.path.join('/kaggle/input/state-farm-distracted-driver-detection/imgs/train',class_,image[0]) #Source Directory\n",
    "        dest = os.path.join('/kaggle/working/master_data/validation',class_,image[0]) #Destination Directory\n",
    "        copyfile(source,dest) #Copying file from source to destination\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf #Importing tensorflow library\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator #Importing ImageDataGenerator library to easily manage \n",
    "#and create the training and validation dataset\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "#Adam Optimizer\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "#Callbacks to stop the epochs if the change in accuracy is not significant\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten,Dropout\n",
    "#Importing various layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_11 (Conv2D)           (None, 128, 128, 32)      416       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 64, 64, 64)        8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 32, 32, 128)       32896     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 500)               16384500  \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                5010      \n",
      "=================================================================\n",
      "Total params: 16,431,078\n",
      "Trainable params: 16,431,078\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Creating the model by adding various layers such as the CONV2D, MaxPooling2D, dropout layer, dense layer etc.\n",
    "model = tf.keras.models.Sequential([\n",
    "    Conv2D(32,(2,2),activation='relu',input_shape = (128,128,3),kernel_initializer='glorot_normal',padding='same'),\n",
    "    MaxPooling2D(pool_size = (2,2),),\n",
    "    Conv2D(64,(2,2),activation = 'relu',padding='same',kernel_initializer='glorot_normal'),\n",
    "    MaxPooling2D(pool_size = (2,2)),\n",
    "    Conv2D(128,(2,2),activation = 'relu',padding='same',kernel_initializer='glorot_normal'),\n",
    "    MaxPooling2D(pool_size = (2,2)),\n",
    "    Dropout(0.5),\n",
    "    Flatten(),\n",
    "    Dense(500,activation = 'relu',kernel_initializer='glorot_normal'),\n",
    "    Dropout(0.5),\n",
    "    Dense(10,activation = 'softmax',kernel_initializer='glorot_normal')\n",
    "])\n",
    "#Compiling the model with the loss, optimizer and metrics used for testing the model\n",
    "model.compile(optimizer='rmsprop',loss = 'categorical_crossentropy',\n",
    "             metrics = ['accuracy'])\n",
    "#Checking the model summary if correct or not\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17934 images belonging to 10 classes.\n",
      "Found 4490 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dir = '/kaggle/working/master_data/training' #Directory containing the training data\n",
    "test_dir = '/kaggle/working/master_data/validation' #Directory containing the testing data\n",
    "\n",
    "train_data_gen = ImageDataGenerator(1.0/255) #Image Data Generator for the trainging dataset\n",
    "train_generator = train_data_gen.flow_from_directory(\n",
    "    train_dir , target_size = (128,128), class_mode = 'categorical',\n",
    "    batch_size = 128\n",
    ") #Creating the training_generator with specified parameters\n",
    "test_data_gen = ImageDataGenerator(1.0/255) #Image Data Generator for the validation dataset\n",
    "test_generator = test_data_gen.flow_from_directory(\n",
    "    test_dir , target_size = (128,128), class_mode = 'categorical',\n",
    "    batch_size = 128\n",
    ") #Creating the validation_generator with specified parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor = 'accuracy',patience = 3, min_delta = 0.01)\n",
    "#Defining the callback to stop the model with accuracy as the metrics and min_delta 1% and patience 3 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "141/141 [==============================] - 290s 2s/step - loss: 67.9278 - accuracy: 0.3987 - val_loss: 5.3390 - val_accuracy: 0.1486\n",
      "Epoch 2/20\n",
      "141/141 [==============================] - 289s 2s/step - loss: 0.8968 - accuracy: 0.8457 - val_loss: 9.8045 - val_accuracy: 0.1539\n",
      "Epoch 3/20\n",
      "141/141 [==============================] - 303s 2s/step - loss: 0.4198 - accuracy: 0.9213 - val_loss: 7.7563 - val_accuracy: 0.1904\n",
      "Epoch 4/20\n",
      "141/141 [==============================] - 288s 2s/step - loss: 0.3425 - accuracy: 0.9368 - val_loss: 7.2158 - val_accuracy: 0.2080\n",
      "Epoch 5/20\n",
      "141/141 [==============================] - 305s 2s/step - loss: 0.1958 - accuracy: 0.9564 - val_loss: 10.9925 - val_accuracy: 0.2336\n",
      "Epoch 6/20\n",
      "141/141 [==============================] - 288s 2s/step - loss: 0.4608 - accuracy: 0.9414 - val_loss: 12.1593 - val_accuracy: 0.2285\n",
      "Epoch 7/20\n",
      "141/141 [==============================] - 308s 2s/step - loss: 0.1280 - accuracy: 0.9747 - val_loss: 12.8780 - val_accuracy: 0.2354\n",
      "Epoch 8/20\n",
      "141/141 [==============================] - 290s 2s/step - loss: 0.0893 - accuracy: 0.9790 - val_loss: 13.9765 - val_accuracy: 0.2350\n",
      "Epoch 9/20\n",
      "141/141 [==============================] - 303s 2s/step - loss: 0.1573 - accuracy: 0.9759 - val_loss: 14.6141 - val_accuracy: 0.2454\n",
      "Epoch 10/20\n",
      "141/141 [==============================] - 289s 2s/step - loss: 0.0708 - accuracy: 0.9843 - val_loss: 19.8748 - val_accuracy: 0.2394\n",
      "Epoch 11/20\n",
      "141/141 [==============================] - 290s 2s/step - loss: 0.0781 - accuracy: 0.9838 - val_loss: 13.7125 - val_accuracy: 0.2383\n",
      "Epoch 12/20\n",
      "141/141 [==============================] - 302s 2s/step - loss: 0.0531 - accuracy: 0.9874 - val_loss: 19.9976 - val_accuracy: 0.2296\n",
      "Epoch 13/20\n",
      "141/141 [==============================] - 287s 2s/step - loss: 0.0704 - accuracy: 0.9855 - val_loss: 20.9309 - val_accuracy: 0.2412\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff6ec5c2150>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_generator,epochs = 20, verbose =1, validation_data=test_generator,callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from skimage import io \n",
    "from skimage.transform import resize\n",
    "size = (128,128)\n",
    "image_dir = '/kaggle/input/state-farm-distracted-driver-detection/imgs/test'\n",
    "image_list = glob.glob(image_dir+'/*')\n",
    "x_test= [] #Creating the testing dataset by iterating the test directory and resizing the images according to the expected data.\n",
    "for i,imgfile in enumerate(image_list):\n",
    "    if(i%10000==0):\n",
    "        print(i)\n",
    "    img = io.imread(imgfile)\n",
    "    img = resize(img,size)\n",
    "    x_test.append(img)\n",
    "    #appending the current image to x_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediciting the result and printing it\n",
    "x_test = np.array(x_test) \n",
    "print(x_test.shape)\n",
    "y_pred = model.predict(x_test)\n",
    "print(y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
